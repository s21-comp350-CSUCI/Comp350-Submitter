# How the back end works _v 1.0_   
Authored by Sam Mazarei  
### Before the backend runs, a student submission is generated...  
When a student submission is generated, two objects will bu uploaded to the
submitter S3 bucket. One is a single .py file provided by the student(s),
and a .json file generated by the front end logic containing all the requsit data for the backend to begin processing the submission.  
This json file will contain the following:
* submissionid  : a 128 bit MD5 Hash unique to the specific students, admin, event,  and problem.
* admin         : The admin's unique identifier (e.g "m.soltys").  
* event         : A string identifier that is unique to the admin.
* problem       : A string identifier unique to the event.
* tokens        : A(n) list/array of tokens generated by the front end upon event registration.  

An example:  
[submission_example.json](./json/submission_example.json)
```
{
  "subid": "fc55c0190dde2bc413d8d1e79fb8cca2",
  "admin": "m.soltys",
  "event": "aws_labs",
  "problem": "lab5_containers",
  "tokens": [
    "d823640ab3b0f7a4a2bc9fc89661e940",
    "240669d4326dea48bba75e066b90b76f",
    "4b31d568d86a9350d746c7c2fe9bf5c8"
  ]
}        
```  
The file structure of the S3 bucket is very important. We will be using a pseudo file system. As of this writing the top
level directory of the bucket will contain two sub directories:  
* /submissions/ 
* /output/  
* we may have to consider placing all the event parameters into the bucket as well...  

When a new submission is submitted, both a json and python file will be generated in a new directory. For example:
`/submissions/m.soltys/aws_labs/lab5_containers/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`   
and `/submissions/m.soltys/aws_labs/lab5_containers/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`  

## A new object/file in the S3 bucket triggers a lambda function...
  
A new object in the submitter S3 bucket triggers a lambda function written in python. This lambda function will analyse 
the name of the new object, and if the new object is a student submission json file, a message is generated and sent 
to the submitter SQS queue. This message is a json file and, as of this writing, contains just one key : value pair :
```
{
  "subdata" : "fc55c0190dde2bc413d8d1e79fb8cca2.json"
}        
``` 
## The back end makes its inglorious entrance...  
The back ends app will first retrieve the next message from the SQS queue. Using our own 
back end module of functions documented [here](./.backendmethods.md) we begin.  
### Retrieve neccessary files and data
* extracting the name of the json file from the SQS message.  
* creating a directory using the subid from the subdata filename, for example  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/`   
* changing present working directories into the newly cerated directory, from there retrieving both the newly submitted 
  json and python files from the S3 bucket, for example:  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`
    
### Query database for test case parameters
From the data in the json file, we 
* query the database for the test inputs and outputs, and generate files for comparison, for example `test.in` and `test.out`.   

These files will be formatted so that individual test case input for the specific problem is placed on a new line in `test.in`, 
and the appropriate output expected for each input is placed on a new line in `test.out`.   
The directory structure at this point:  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.in`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.out`  

### Execute submitted code in container  
At this point we have the code to execute, the inputs to run, and the appropriate outputs for comparison.
